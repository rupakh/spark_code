{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68ecc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Second PySpark Code using Jupyter Notebook\n",
    "\n",
    "'''\n",
    "\n",
    "In this program, I try and retrieve data of two tables from MySQL to PySpark, \n",
    "perform a join and then load the dataset into a new table in MySQL\n",
    "\n",
    "'''\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42722e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['SPARK_HOME'] = sys.executable\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('JoiningTwoTablesCode').config(\"spark.jars\", \"mysql-connector-j-8.1.0\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23dd8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'actor' table from the database into the actor Spark dataframe\n",
    "\n",
    "actor = spark.read.format(\"jdbc\").option(\"driver\",\"com.mysql.cj.jdbc.Driver\").option(\"url\", \"jdbc:mysql://localhost:3306/sakila\").option(\"dbtable\", \"actor\").option(\"user\", \"root\").option(\"password\", \"Usha@789\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f1656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'film_actor' table from the database into the film_actor Spark dataframe\n",
    "\n",
    "\n",
    "film_actor = spark.read.format(\"jdbc\").option(\"driver\",\"com.mysql.cj.jdbc.Driver\").option(\"url\", \"jdbc:mysql://localhost:3306/sakila\").option(\"dbtable\", \"film_actor\").option(\"user\", \"root\").option(\"password\", \"Usha@789\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9056083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the 'film' table from the database into the film Spark dataframe\n",
    "\n",
    "film = spark.read.format(\"jdbc\").option(\"driver\",\"com.mysql.cj.jdbc.Driver\").option(\"url\", \"jdbc:mysql://localhost:3306/sakila\").option(\"dbtable\", \"film\").option(\"user\", \"root\").option(\"password\", \"Usha@789\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d168061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+-------------------+\n",
      "|actor_id|first_name|last_name|        last_update|\n",
      "+--------+----------+---------+-------------------+\n",
      "|       1|  PENELOPE|  GUINESS|2006-02-15 04:34:33|\n",
      "+--------+----------+---------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first row of the actor dataframe\n",
    "\n",
    "actor.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a8fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+-------------------+\n",
      "|actor_id|film_id|        last_update|\n",
      "+--------+-------+-------------------+\n",
      "|       1|      1|2006-02-15 05:05:03|\n",
      "+--------+-------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first row of the film_actor dataframe\n",
    "\n",
    "film_actor.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f572c7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
      "|film_id|           title|         description|release_year|language_id|original_language_id|rental_duration|rental_rate|length|replacement_cost|rating|    special_features|        last_update|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
      "|      1|ACADEMY DINOSAUR|A Epic Drama of a...|  2006-01-01|          1|                NULL|              6|       0.99|    86|           20.99| PG   |Deleted Scenes,Be...|2006-02-15 05:03:42|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+-------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the first row of the film dataframe\n",
    "\n",
    "film.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772558ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     200|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    5462|\n",
      "+--------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|    1000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Working with SQL\n",
    "\n",
    "# Creating temporary views on the above dataframes to run SQL queries\n",
    "\n",
    "actor.createOrReplaceTempView(\"actor_view\")\n",
    "spark.sql(\"SELECT count(*) from actor_view\").show()\n",
    "\n",
    "film_actor.createOrReplaceTempView(\"film_actor_view\")\n",
    "spark.sql(\"SELECT count(*) from film_actor_view\").show()\n",
    "\n",
    "film.createOrReplaceTempView(\"film_view\")\n",
    "spark.sql(\"SELECT count(*) from film_view\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06d933a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_three_tables dataframe will contain data after joining three temporary views using SQL\n",
    "\n",
    "join_three_tables = spark.sql(\"SELECT AV.first_name,AV.last_name,FV.title,FV.description,FV.rating from actor_view AV INNER JOIN film_actor_view FAV ON FAV.actor_id = AV.actor_id INNER JOIN film_view FV ON FV.film_id = FAV.film_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0b6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will create a table named actor_film with the data stored in join_three_tables dataframe\n",
    "\n",
    "join_three_tables.write.format(\"jdbc\").option(\"driver\",\"com.mysql.cj.jdbc.Driver\").option(\"url\", \"jdbc:mysql://localhost:3306/sakila\").option(\"dbtable\", \"actor_film\").option(\"user\", \"root\").option(\"password\", \"Usha@789\").save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
